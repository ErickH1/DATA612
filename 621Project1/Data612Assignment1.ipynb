{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data 612 Assignment 1"
      ],
      "metadata": {
        "id": "5o-p-_DzHk8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "lvLccqx-Hg0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our recommender system recommends data science books to readers based on their historical ratings. By predicting ratings when a new readerâ€“book pair is encountered, the system can suggest books the reader is likely to enjoy."
      ],
      "metadata": {
        "id": "Z9C0jkb3HYgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "ru7iQ1fLHrNk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UqYFYwh3_AiL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'user': [\n",
        "        'A', 'A', 'A',\n",
        "        'B', 'B', 'B', 'B',\n",
        "        'C', 'C', 'C', 'C',\n",
        "        'D', 'D', 'D',\n",
        "        'E', 'E', 'E', 'E'\n",
        "    ],\n",
        "    'item': [\n",
        "        'book1', 'book2', 'book3',\n",
        "        'book1', 'book3', 'book4', 'book5',\n",
        "        'book2', 'book3', 'book4', 'book5',\n",
        "        'book1', 'book2', 'book3',\n",
        "        'book1', 'book2', 'book4', 'book5'\n",
        "    ],\n",
        "    'rating': [\n",
        "        5, 3, 4,\n",
        "        4, 2, 1, 3,\n",
        "        5, 4, 3, 3,\n",
        "        3, 3, 4,\n",
        "        2, 5, 4, 3\n",
        "    ]\n",
        "}\n",
        "\n",
        "ratings_df = pd.DataFrame(data)\n",
        "print(\"Original Ratings:\")\n",
        "print(ratings_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Yd1EQSgBdd1",
        "outputId": "290b4149-b687-4abc-fb3b-f64221fbe517"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Ratings DataFrame:\n",
            "   user   item  rating\n",
            "0     A  book1       5\n",
            "1     A  book2       3\n",
            "2     A  book3       4\n",
            "3     B  book1       4\n",
            "4     B  book3       2\n",
            "5     B  book4       1\n",
            "6     B  book5       3\n",
            "7     C  book2       5\n",
            "8     C  book3       4\n",
            "9     C  book4       3\n",
            "10    C  book5       3\n",
            "11    D  book1       3\n",
            "12    D  book2       3\n",
            "13    D  book3       4\n",
            "14    E  book1       2\n",
            "15    E  book2       5\n",
            "16    E  book4       4\n",
            "17    E  book5       3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_item_matrix = ratings_df.pivot(index='user', columns='item', values='rating')\n",
        "print(\"\\nUser-Item Matrix:\")\n",
        "print(user_item_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqbDiRYuBdvz",
        "outputId": "f93cd13b-2918-4d1b-d28d-0251daedf0bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User-Item Matrix:\n",
            "item  book1  book2  book3  book4  book5\n",
            "user                                   \n",
            "A       5.0    3.0    4.0    NaN    NaN\n",
            "B       4.0    NaN    2.0    1.0    3.0\n",
            "C       NaN    5.0    4.0    3.0    3.0\n",
            "D       3.0    3.0    4.0    NaN    NaN\n",
            "E       2.0    5.0    NaN    4.0    3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(612)\n",
        "\n",
        "mask = np.random.rand(len(ratings_df)) < 0.8\n",
        "train_df = ratings_df[mask].reset_index(drop=True)\n",
        "test_df = ratings_df[~mask].reset_index(drop=True)\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(train_df)\n",
        "print(\"\\nTest Data:\")\n",
        "print(test_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2Fz5PXnBd_s",
        "outputId": "dc5b5304-a132-4c98-f427-d2778cb7097c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "   user   item  rating\n",
            "0     A  book1       5\n",
            "1     A  book2       3\n",
            "2     B  book1       4\n",
            "3     B  book4       1\n",
            "4     B  book5       3\n",
            "5     C  book3       4\n",
            "6     C  book4       3\n",
            "7     D  book2       3\n",
            "8     D  book3       4\n",
            "9     E  book2       5\n",
            "10    E  book4       4\n",
            "11    E  book5       3\n",
            "\n",
            "Test Data:\n",
            "  user   item  rating\n",
            "0    A  book3       4\n",
            "1    B  book3       2\n",
            "2    C  book2       5\n",
            "3    C  book5       3\n",
            "4    D  book1       3\n",
            "5    E  book1       2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_avg = train_df['rating'].mean()\n",
        "print(f\"\\nGlobal Average Rating: {global_avg:.2f}\")\n",
        "\n",
        "train_df['pred_raw'] = global_avg\n",
        "test_df['pred_raw'] = global_avg\n",
        "\n",
        "rmse_train_raw = np.sqrt(mean_squared_error(train_df['rating'], train_df['pred_raw']))\n",
        "rmse_test_raw = np.sqrt(mean_squared_error(test_df['rating'], test_df['pred_raw']))\n",
        "print(f\"Raw Average RMSE (Training): {rmse_train_raw:.2f}\")\n",
        "print(f\"Raw Average RMSE (Test): {rmse_test_raw:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC3hDPIzBeND",
        "outputId": "23dbd5d9-1082-49a3-a0ae-7df47e8ccd88"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Global Average Rating: 3.50\n",
            "Raw Average RMSE (Training): 1.04\n",
            "Raw Average RMSE (Test): 1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_bias = train_df.groupby('user')['rating'].mean() - global_avg\n",
        "\n",
        "item_bias = train_df.groupby('item')['rating'].mean() - global_avg\n",
        "\n",
        "print(\"\\nUser Biases:\")\n",
        "print(user_bias)\n",
        "print(\"\\nItem Biases:\")\n",
        "print(item_bias)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJEVL7PwEQ1Q",
        "outputId": "40488b82-175e-4f0f-bf21-64d968c55c6e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User Biases:\n",
            "user\n",
            "A    0.500000\n",
            "B   -0.833333\n",
            "C    0.000000\n",
            "D    0.000000\n",
            "E    0.500000\n",
            "Name: rating, dtype: float64\n",
            "\n",
            "Item Biases:\n",
            "item\n",
            "book1    1.000000\n",
            "book2    0.166667\n",
            "book3    0.500000\n",
            "book4   -0.833333\n",
            "book5   -0.500000\n",
            "Name: rating, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_predict(row):\n",
        "    u_bias = user_bias.get(row['user'], 0)\n",
        "    i_bias = item_bias.get(row['item'], 0)\n",
        "    return global_avg + u_bias + i_bias\n",
        "\n",
        "train_df['pred_baseline'] = train_df.apply(baseline_predict, axis=1)\n",
        "test_df['pred_baseline'] = test_df.apply(baseline_predict, axis=1)\n",
        "\n",
        "print(\"\\nTraining predictions:\")\n",
        "print(train_df[['user', 'item', 'rating', 'pred_baseline']])\n",
        "print(\"\\nTest predictions:\")\n",
        "print(test_df[['user', 'item', 'rating', 'pred_baseline']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaHfZEgIEVWe",
        "outputId": "993645c2-7c65-4531-ab43-71ada25f19b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training predictions (first few rows):\n",
            "   user   item  rating  pred_baseline\n",
            "0     A  book1       5       5.000000\n",
            "1     A  book2       3       4.166667\n",
            "2     B  book1       4       3.666667\n",
            "3     B  book4       1       1.833333\n",
            "4     B  book5       3       2.166667\n",
            "5     C  book3       4       4.000000\n",
            "6     C  book4       3       2.666667\n",
            "7     D  book2       3       3.666667\n",
            "8     D  book3       4       4.000000\n",
            "9     E  book2       5       4.166667\n",
            "10    E  book4       4       3.166667\n",
            "11    E  book5       3       3.500000\n",
            "\n",
            "Test predictions (first few rows):\n",
            "  user   item  rating  pred_baseline\n",
            "0    A  book3       4       4.500000\n",
            "1    B  book3       2       3.166667\n",
            "2    C  book2       5       3.666667\n",
            "3    C  book5       3       3.000000\n",
            "4    D  book1       3       4.500000\n",
            "5    E  book1       2       5.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_train_bl = np.sqrt(mean_squared_error(train_df['rating'], train_df['pred_baseline']))\n",
        "rmse_test_bl = np.sqrt(mean_squared_error(test_df['rating'], test_df['pred_baseline']))\n",
        "print(f\"\\nBaseline Predictor RMSE (Training): {rmse_train_bl:.2f}\")\n",
        "print(f\"Baseline Predictor RMSE (Test): {rmse_test_bl:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veSmRkqTEXPR",
        "outputId": "0dd9c19b-21a0-48ba-f6a3-b056a458a92c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Baseline Predictor RMSE (Training): 0.65\n",
            "Baseline Predictor RMSE (Test): 1.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "c5GywZhXHyrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion a simple model was built that predicts every rating as the global average. It gives RMSEs of about 1.04 (training) and 1.12 (test).\n",
        "\n",
        "Incorporating user and item biases improve training performances, RMSE improving to 0.65, this is because it adjusts for known tendencies. However, on the test set, the RMSE increased to 1.56. This means that the biases capture the training data well, but they overfit on the test dataset. However this is to be expected since we are working with a toy dataset with very few data."
      ],
      "metadata": {
        "id": "Ycekxsd2H0Wi"
      }
    }
  ]
}